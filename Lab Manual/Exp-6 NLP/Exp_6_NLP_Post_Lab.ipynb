{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on_Hb7ldhV7D",
        "outputId": "0591edd1-a55e-4b95-dc02-06c80382b591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# 1.\tLoad the basic libraries and packages\n",
        "\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from spacy import displacy\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Text\n",
        "\n",
        "text = \"Natural Language Processing (NLP) is a field of AI that focuses on the interaction between computers and human language. It enables machines to read, understand, and interpret human language. NLP techniques include tokenization, stemming, lemmatization, and part-of-speech tagging to process text data effectively. Sentiment analysis is a popular NLP application used to determine the emotional tone of text. Chatbots and virtual assistants leverage NLP to engage in human-like conversations. Named Entity Recognition (NER) identifies key entities like names, dates, and locations in text. Machine translation, such as Google Translate, is powered by NLP to convert text between languages. NLP models like GPT and BERT have revolutionized text generation and understanding. Speech recognition systems rely on NLP to convert spoken words into text. Ethical concerns in NLP include bias in language models and the misuse of AI-generated text.\"\n"
      ],
      "metadata": {
        "id": "1qgrLuqyk5xq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Tokenization\n",
        "\n",
        "sent_tokens = sent_tokenize(text)\n",
        "word_tokens = word_tokenize(text)\n",
        "\n",
        "print(\"\\nSentence Tokenization:\")\n",
        "print(sent_tokens)\n",
        "\n",
        "print(\"\\nWord Tokenization:\")\n",
        "print(word_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIclUTcvlKpj",
        "outputId": "97da3718-aaf6-457b-ba10-f3f47b954365"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence Tokenization:\n",
            "['Natural Language Processing (NLP) is a field of AI that focuses on the interaction between computers and human language.', 'It enables machines to read, understand, and interpret human language.', 'NLP techniques include tokenization, stemming, lemmatization, and part-of-speech tagging to process text data effectively.', 'Sentiment analysis is a popular NLP application used to determine the emotional tone of text.', 'Chatbots and virtual assistants leverage NLP to engage in human-like conversations.', 'Named Entity Recognition (NER) identifies key entities like names, dates, and locations in text.', 'Machine translation, such as Google Translate, is powered by NLP to convert text between languages.', 'NLP models like GPT and BERT have revolutionized text generation and understanding.', 'Speech recognition systems rely on NLP to convert spoken words into text.', 'Ethical concerns in NLP include bias in language models and the misuse of AI-generated text.']\n",
            "\n",
            "Word Tokenization:\n",
            "['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'field', 'of', 'AI', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'human', 'language', '.', 'It', 'enables', 'machines', 'to', 'read', ',', 'understand', ',', 'and', 'interpret', 'human', 'language', '.', 'NLP', 'techniques', 'include', 'tokenization', ',', 'stemming', ',', 'lemmatization', ',', 'and', 'part-of-speech', 'tagging', 'to', 'process', 'text', 'data', 'effectively', '.', 'Sentiment', 'analysis', 'is', 'a', 'popular', 'NLP', 'application', 'used', 'to', 'determine', 'the', 'emotional', 'tone', 'of', 'text', '.', 'Chatbots', 'and', 'virtual', 'assistants', 'leverage', 'NLP', 'to', 'engage', 'in', 'human-like', 'conversations', '.', 'Named', 'Entity', 'Recognition', '(', 'NER', ')', 'identifies', 'key', 'entities', 'like', 'names', ',', 'dates', ',', 'and', 'locations', 'in', 'text', '.', 'Machine', 'translation', ',', 'such', 'as', 'Google', 'Translate', ',', 'is', 'powered', 'by', 'NLP', 'to', 'convert', 'text', 'between', 'languages', '.', 'NLP', 'models', 'like', 'GPT', 'and', 'BERT', 'have', 'revolutionized', 'text', 'generation', 'and', 'understanding', '.', 'Speech', 'recognition', 'systems', 'rely', 'on', 'NLP', 'to', 'convert', 'spoken', 'words', 'into', 'text', '.', 'Ethical', 'concerns', 'in', 'NLP', 'include', 'bias', 'in', 'language', 'models', 'and', 'the', 'misuse', 'of', 'AI-generated', 'text', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Filtration\n",
        "\n",
        "filtered_tokens = [word for word in word_tokens if word.isalpha()]\n",
        "print(\"After Filtration (Only Words):\")\n",
        "print(filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRQ2tLifl2ho",
        "outputId": "50a71ff8-259f-47e8-cfed-9d9e70143b0c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Filtration (Only Words):\n",
            "['Natural', 'Language', 'Processing', 'NLP', 'is', 'a', 'field', 'of', 'AI', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'human', 'language', 'It', 'enables', 'machines', 'to', 'read', 'understand', 'and', 'interpret', 'human', 'language', 'NLP', 'techniques', 'include', 'tokenization', 'stemming', 'lemmatization', 'and', 'tagging', 'to', 'process', 'text', 'data', 'effectively', 'Sentiment', 'analysis', 'is', 'a', 'popular', 'NLP', 'application', 'used', 'to', 'determine', 'the', 'emotional', 'tone', 'of', 'text', 'Chatbots', 'and', 'virtual', 'assistants', 'leverage', 'NLP', 'to', 'engage', 'in', 'conversations', 'Named', 'Entity', 'Recognition', 'NER', 'identifies', 'key', 'entities', 'like', 'names', 'dates', 'and', 'locations', 'in', 'text', 'Machine', 'translation', 'such', 'as', 'Google', 'Translate', 'is', 'powered', 'by', 'NLP', 'to', 'convert', 'text', 'between', 'languages', 'NLP', 'models', 'like', 'GPT', 'and', 'BERT', 'have', 'revolutionized', 'text', 'generation', 'and', 'understanding', 'Speech', 'recognition', 'systems', 'rely', 'on', 'NLP', 'to', 'convert', 'spoken', 'words', 'into', 'text', 'Ethical', 'concerns', 'in', 'NLP', 'include', 'bias', 'in', 'language', 'models', 'and', 'the', 'misuse', 'of', 'text']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Stopwords Removal\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "tokens_without_stopwords = [word for word in filtered_tokens if word.lower() not in stop_words]\n",
        "print(\"After Stopwords Removal:\")\n",
        "print(tokens_without_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Sv7gs3wm3On",
        "outputId": "f2434916-1f3e-42f6-bb74-34d86cdc487e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Stopwords Removal:\n",
            "['Natural', 'Language', 'Processing', 'NLP', 'field', 'AI', 'focuses', 'interaction', 'computers', 'human', 'language', 'enables', 'machines', 'read', 'understand', 'interpret', 'human', 'language', 'NLP', 'techniques', 'include', 'tokenization', 'stemming', 'lemmatization', 'tagging', 'process', 'text', 'data', 'effectively', 'Sentiment', 'analysis', 'popular', 'NLP', 'application', 'used', 'determine', 'emotional', 'tone', 'text', 'Chatbots', 'virtual', 'assistants', 'leverage', 'NLP', 'engage', 'conversations', 'Named', 'Entity', 'Recognition', 'NER', 'identifies', 'key', 'entities', 'like', 'names', 'dates', 'locations', 'text', 'Machine', 'translation', 'Google', 'Translate', 'powered', 'NLP', 'convert', 'text', 'languages', 'NLP', 'models', 'like', 'GPT', 'BERT', 'revolutionized', 'text', 'generation', 'understanding', 'Speech', 'recognition', 'systems', 'rely', 'NLP', 'convert', 'spoken', 'words', 'text', 'Ethical', 'concerns', 'NLP', 'include', 'bias', 'language', 'models', 'misuse', 'text']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. PoS Tagging\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)\n",
        "\n",
        "print(\"Part-of-Speech (PoS) Tagging:\")\n",
        "for token in doc:\n",
        "    print(f\"{token.text:<15} {token.pos_:<10} {token.dep_:<10}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C5j3QQnnJE9",
        "outputId": "a4f34762-dd9e-4e7b-c22f-e8315a8dfa92"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Part-of-Speech (PoS) Tagging:\n",
            "Natural         PROPN      compound  \n",
            "Language        PROPN      compound  \n",
            "Processing      PROPN      nsubj     \n",
            "(               PUNCT      punct     \n",
            "NLP             PROPN      appos     \n",
            ")               PUNCT      punct     \n",
            "is              AUX        ROOT      \n",
            "a               DET        det       \n",
            "field           NOUN       attr      \n",
            "of              ADP        prep      \n",
            "AI              PROPN      pobj      \n",
            "that            PRON       nsubj     \n",
            "focuses         VERB       relcl     \n",
            "on              ADP        prep      \n",
            "the             DET        det       \n",
            "interaction     NOUN       pobj      \n",
            "between         ADP        prep      \n",
            "computers       NOUN       pobj      \n",
            "and             CCONJ      cc        \n",
            "human           ADJ        amod      \n",
            "language        NOUN       conj      \n",
            ".               PUNCT      punct     \n",
            "It              PRON       nsubj     \n",
            "enables         VERB       ROOT      \n",
            "machines        NOUN       nsubj     \n",
            "to              PART       aux       \n",
            "read            VERB       ccomp     \n",
            ",               PUNCT      punct     \n",
            "understand      VERB       conj      \n",
            ",               PUNCT      punct     \n",
            "and             CCONJ      cc        \n",
            "interpret       VERB       conj      \n",
            "human           ADJ        amod      \n",
            "language        NOUN       dobj      \n",
            ".               PUNCT      punct     \n",
            "NLP             PROPN      compound  \n",
            "techniques      NOUN       nsubj     \n",
            "include         VERB       ROOT      \n",
            "tokenization    NOUN       dobj      \n",
            ",               PUNCT      punct     \n",
            "stemming        NOUN       conj      \n",
            ",               PUNCT      punct     \n",
            "lemmatization   NOUN       conj      \n",
            ",               PUNCT      punct     \n",
            "and             CCONJ      cc        \n",
            "part            NOUN       nmod      \n",
            "-               PUNCT      punct     \n",
            "of              ADP        prep      \n",
            "-               PUNCT      punct     \n",
            "speech          NOUN       pobj      \n",
            "tagging         NOUN       conj      \n",
            "to              PART       aux       \n",
            "process         VERB       xcomp     \n",
            "text            NOUN       compound  \n",
            "data            NOUN       dobj      \n",
            "effectively     ADV        advmod    \n",
            ".               PUNCT      punct     \n",
            "Sentiment       NOUN       compound  \n",
            "analysis        NOUN       nsubj     \n",
            "is              AUX        ROOT      \n",
            "a               DET        det       \n",
            "popular         ADJ        amod      \n",
            "NLP             PROPN      compound  \n",
            "application     NOUN       attr      \n",
            "used            VERB       acl       \n",
            "to              PART       aux       \n",
            "determine       VERB       xcomp     \n",
            "the             DET        det       \n",
            "emotional       ADJ        amod      \n",
            "tone            NOUN       dobj      \n",
            "of              ADP        prep      \n",
            "text            NOUN       pobj      \n",
            ".               PUNCT      punct     \n",
            "Chatbots        NOUN       nsubj     \n",
            "and             CCONJ      cc        \n",
            "virtual         ADJ        amod      \n",
            "assistants      NOUN       conj      \n",
            "leverage        VERB       ROOT      \n",
            "NLP             PROPN      dobj      \n",
            "to              PART       aux       \n",
            "engage          VERB       xcomp     \n",
            "in              ADP        prep      \n",
            "human           NOUN       npadvmod  \n",
            "-               PUNCT      punct     \n",
            "like            ADJ        amod      \n",
            "conversations   NOUN       pobj      \n",
            ".               PUNCT      punct     \n",
            "Named           VERB       csubj     \n",
            "Entity          PROPN      compound  \n",
            "Recognition     PROPN      nsubj     \n",
            "(               PUNCT      punct     \n",
            "NER             PROPN      appos     \n",
            ")               PUNCT      punct     \n",
            "identifies      VERB       ROOT      \n",
            "key             ADJ        amod      \n",
            "entities        NOUN       dobj      \n",
            "like            ADP        prep      \n",
            "names           NOUN       pobj      \n",
            ",               PUNCT      punct     \n",
            "dates           NOUN       conj      \n",
            ",               PUNCT      punct     \n",
            "and             CCONJ      cc        \n",
            "locations       NOUN       conj      \n",
            "in              ADP        prep      \n",
            "text            NOUN       pobj      \n",
            ".               PUNCT      punct     \n",
            "Machine         NOUN       compound  \n",
            "translation     NOUN       nsubjpass \n",
            ",               PUNCT      punct     \n",
            "such            ADJ        amod      \n",
            "as              ADP        prep      \n",
            "Google          PROPN      compound  \n",
            "Translate       PROPN      pobj      \n",
            ",               PUNCT      punct     \n",
            "is              AUX        auxpass   \n",
            "powered         VERB       ROOT      \n",
            "by              ADP        agent     \n",
            "NLP             PROPN      pobj      \n",
            "to              PART       aux       \n",
            "convert         VERB       xcomp     \n",
            "text            NOUN       dobj      \n",
            "between         ADP        prep      \n",
            "languages       NOUN       pobj      \n",
            ".               PUNCT      punct     \n",
            "NLP             PROPN      compound  \n",
            "models          NOUN       nsubj     \n",
            "like            ADP        prep      \n",
            "GPT             PROPN      pobj      \n",
            "and             CCONJ      cc        \n",
            "BERT            PROPN      conj      \n",
            "have            AUX        aux       \n",
            "revolutionized  VERB       ROOT      \n",
            "text            NOUN       compound  \n",
            "generation      NOUN       dobj      \n",
            "and             CCONJ      cc        \n",
            "understanding   NOUN       conj      \n",
            ".               PUNCT      punct     \n",
            "Speech          PROPN      compound  \n",
            "recognition     NOUN       compound  \n",
            "systems         NOUN       nsubj     \n",
            "rely            VERB       ROOT      \n",
            "on              ADP        prep      \n",
            "NLP             PROPN      pobj      \n",
            "to              PART       aux       \n",
            "convert         VERB       xcomp     \n",
            "spoken          VERB       amod      \n",
            "words           NOUN       dobj      \n",
            "into            ADP        prep      \n",
            "text            NOUN       pobj      \n",
            ".               PUNCT      punct     \n",
            "Ethical         ADJ        amod      \n",
            "concerns        NOUN       nsubj     \n",
            "in              ADP        prep      \n",
            "NLP             PROPN      pobj      \n",
            "include         VERB       ROOT      \n",
            "bias            NOUN       dobj      \n",
            "in              ADP        prep      \n",
            "language        NOUN       compound  \n",
            "models          NOUN       pobj      \n",
            "and             CCONJ      cc        \n",
            "the             DET        det       \n",
            "misuse          NOUN       conj      \n",
            "of              ADP        prep      \n",
            "AI              PROPN      npadvmod  \n",
            "-               PUNCT      punct     \n",
            "generated       VERB       amod      \n",
            "text            NOUN       pobj      \n",
            ".               PUNCT      punct     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Noun Phrase Chunking\n",
        "\n",
        "print(\"\\nNoun Phrase Chunking:\")\n",
        "for chunk in doc.noun_chunks:\n",
        "    print(f\"Chunk: {chunk.text} | Root: {chunk.root.text} | Dep: {chunk.root.dep_} | Head: {chunk.root.head.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSdIgtMxnuu3",
        "outputId": "61a7c66a-bcb9-4d77-d8b8-3fbb3b94e0fa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Noun Phrase Chunking:\n",
            "Chunk: Natural Language Processing | Root: Processing | Dep: nsubj | Head: is\n",
            "Chunk: NLP | Root: NLP | Dep: appos | Head: Processing\n",
            "Chunk: a field | Root: field | Dep: attr | Head: is\n",
            "Chunk: AI | Root: AI | Dep: pobj | Head: of\n",
            "Chunk: that | Root: that | Dep: nsubj | Head: focuses\n",
            "Chunk: the interaction | Root: interaction | Dep: pobj | Head: on\n",
            "Chunk: computers | Root: computers | Dep: pobj | Head: between\n",
            "Chunk: human language | Root: language | Dep: conj | Head: computers\n",
            "Chunk: It | Root: It | Dep: nsubj | Head: enables\n",
            "Chunk: machines | Root: machines | Dep: nsubj | Head: read\n",
            "Chunk: human language | Root: language | Dep: dobj | Head: interpret\n",
            "Chunk: NLP techniques | Root: techniques | Dep: nsubj | Head: include\n",
            "Chunk: tokenization | Root: tokenization | Dep: dobj | Head: include\n",
            "Chunk: stemming | Root: stemming | Dep: conj | Head: tokenization\n",
            "Chunk: lemmatization | Root: lemmatization | Dep: conj | Head: stemming\n",
            "Chunk: speech | Root: speech | Dep: pobj | Head: of\n",
            "Chunk: text data | Root: data | Dep: dobj | Head: process\n",
            "Chunk: Sentiment analysis | Root: analysis | Dep: nsubj | Head: is\n",
            "Chunk: a popular NLP application | Root: application | Dep: attr | Head: is\n",
            "Chunk: the emotional tone | Root: tone | Dep: dobj | Head: determine\n",
            "Chunk: text | Root: text | Dep: pobj | Head: of\n",
            "Chunk: Chatbots | Root: Chatbots | Dep: nsubj | Head: leverage\n",
            "Chunk: virtual assistants | Root: assistants | Dep: conj | Head: Chatbots\n",
            "Chunk: NLP | Root: NLP | Dep: dobj | Head: leverage\n",
            "Chunk: human-like conversations | Root: conversations | Dep: pobj | Head: in\n",
            "Chunk: Entity Recognition | Root: Recognition | Dep: nsubj | Head: identifies\n",
            "Chunk: NER | Root: NER | Dep: appos | Head: Recognition\n",
            "Chunk: key entities | Root: entities | Dep: dobj | Head: identifies\n",
            "Chunk: names | Root: names | Dep: pobj | Head: like\n",
            "Chunk: dates | Root: dates | Dep: conj | Head: names\n",
            "Chunk: locations | Root: locations | Dep: conj | Head: dates\n",
            "Chunk: text | Root: text | Dep: pobj | Head: in\n",
            "Chunk: Machine translation | Root: translation | Dep: nsubjpass | Head: powered\n",
            "Chunk: Google Translate | Root: Translate | Dep: pobj | Head: as\n",
            "Chunk: NLP | Root: NLP | Dep: pobj | Head: by\n",
            "Chunk: text | Root: text | Dep: dobj | Head: convert\n",
            "Chunk: languages | Root: languages | Dep: pobj | Head: between\n",
            "Chunk: NLP models | Root: models | Dep: nsubj | Head: revolutionized\n",
            "Chunk: GPT | Root: GPT | Dep: pobj | Head: like\n",
            "Chunk: BERT | Root: BERT | Dep: conj | Head: GPT\n",
            "Chunk: text generation | Root: generation | Dep: dobj | Head: revolutionized\n",
            "Chunk: understanding | Root: understanding | Dep: conj | Head: generation\n",
            "Chunk: Speech recognition systems | Root: systems | Dep: nsubj | Head: rely\n",
            "Chunk: NLP | Root: NLP | Dep: pobj | Head: on\n",
            "Chunk: spoken words | Root: words | Dep: dobj | Head: convert\n",
            "Chunk: text | Root: text | Dep: pobj | Head: into\n",
            "Chunk: Ethical concerns | Root: concerns | Dep: nsubj | Head: include\n",
            "Chunk: NLP | Root: NLP | Dep: pobj | Head: in\n",
            "Chunk: bias | Root: bias | Dep: dobj | Head: include\n",
            "Chunk: language models | Root: models | Dep: pobj | Head: in\n",
            "Chunk: the misuse | Root: misuse | Dep: conj | Head: bias\n",
            "Chunk: AI-generated text | Root: text | Dep: pobj | Head: of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Dependency Parsing\n",
        "\n",
        "print(\"Dependency Parsing Visualization:\")\n",
        "\n",
        "displacy.render(nlp(\"I am Learning Artificial Intelligence at 11:40AM in MA112.\") , style = \"dep\" , jupyter = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "MKICozRgn5V1",
        "outputId": "8fe89038-ee9b-454f-c00f-10ff218ffc89"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependency Parsing Visualization:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"9e3140f39829427c8a1b1c81c02344d2-0\" class=\"displacy\" width=\"1625\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">am</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Learning</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Artificial</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Intelligence</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">at</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">11:40AM</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">MA112.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9e3140f39829427c8a1b1c81c02344d2-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,177.0 390.0,177.0 390.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9e3140f39829427c8a1b1c81c02344d2-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9e3140f39829427c8a1b1c81c02344d2-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9e3140f39829427c8a1b1c81c02344d2-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9e3140f39829427c8a1b1c81c02344d2-0-2\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9e3140f39829427c8a1b1c81c02344d2-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9e3140f39829427c8a1b1c81c02344d2-0-3\" stroke-width=\"2px\" d=\"M420,352.0 C420,177.0 740.0,177.0 740.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9e3140f39829427c8a1b1c81c02344d2-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M740.0,354.0 L748.0,342.0 732.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9e3140f39829427c8a1b1c81c02344d2-0-4\" stroke-width=\"2px\" d=\"M420,352.0 C420,89.5 920.0,89.5 920.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9e3140f39829427c8a1b1c81c02344d2-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M920.0,354.0 L928.0,342.0 912.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9e3140f39829427c8a1b1c81c02344d2-0-5\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9e3140f39829427c8a1b1c81c02344d2-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1085.0,354.0 L1093.0,342.0 1077.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9e3140f39829427c8a1b1c81c02344d2-0-6\" stroke-width=\"2px\" d=\"M420,352.0 C420,2.0 1275.0,2.0 1275.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9e3140f39829427c8a1b1c81c02344d2-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1275.0,354.0 L1283.0,342.0 1267.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9e3140f39829427c8a1b1c81c02344d2-0-7\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9e3140f39829427c8a1b1c81c02344d2-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1435.0,354.0 L1443.0,342.0 1427.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}