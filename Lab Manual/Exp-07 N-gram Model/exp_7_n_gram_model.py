# -*- coding: utf-8 -*-
"""Exp_7_N_gram_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xnE8oSF8RQMAuHmu6ifqsfeoQLAbXAiE
"""

# 1. Load Necessary Modules

import numpy as np
import nltk
import networkx as nx
from collections import Counter, defaultdict
from itertools import combinations
from nltk.corpus import stopwords as nltk_stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import matplotlib.pyplot as plt
import math

# Download necessary NLTK resources
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt_tab')

# 2. Initialize the Document

text = """
I am learning natural language processing
Natural language processing is the important module of subject artificial intelligence
This domain has seen many recent advancements in terms of its execution
"""

# 3. Tokenize the Document

tokens = word_tokenize(text.lower())

print("Tokens :- ")

for token in tokens :
  print(token)

# 4.  Preprocessing (Stopword Removal and Lemmatization)

stop_words = set(nltk_stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

# Remove stopwords and lemmatize tokens
filtered_tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalnum() and word not in stop_words]
print("Filtered Tokens:", filtered_tokens)

# 5. Generate N-Grams

def generate_n_grams(tokens, n):
    """Generates N-grams from tokenized words."""
    n_grams = [tuple(tokens[i:i + n]) for i in range(len(tokens) - n + 1)]
    return n_grams

# Generate bigrams
n = 2
n_grams = generate_n_grams(filtered_tokens, n)
print(f"{n}-grams:", n_grams)

# 6. Train the N-Gram Model

def train_grams(n_grams):
    """Trains the N-gram model by counting occurrences."""
    model = defaultdict(Counter)

    for ngram in n_grams:
        prefix = ngram[:-1]
        next_gram = ngram[-1]
        model[prefix][next_gram] += 1

    return model

# Train the model
model = train_grams(n_grams)

# 7. Predict the Next Word

def predict_next_word(model, prefix_words):
    """Predicts the next word given the prefix."""
    if isinstance(prefix_words, str):
        prefix_words = prefix_words.split(" ")

    prefix = tuple(prefix_words)

    if prefix in model:
        return model[prefix].most_common(1)
    else:
        return "No Prediction"

print("Prediction:", predict_next_word(model, ("natural",)))
print("Prediction:", predict_next_word(model, ("language",)))
print("Prediction:", predict_next_word(model, ("artificial",)))